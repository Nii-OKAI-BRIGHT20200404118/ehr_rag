{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e9a0b49-3529-4839-b03c-7ce412274022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from typing import List, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "from llama_index.core import VectorStoreIndex, Settings, Document\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from httpx import Timeout, RequestError, HTTPStatusError, TimeoutException\n",
    "import asyncio\n",
    "import tenacity\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b2f832-8ff3-4e72-adb2-25ad6913c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "@dataclass\n",
    "class OllamaConfig:\n",
    "    llm_model: str = \"qwen2:1.5b\"\n",
    "    #llm_model: str = \"tinyllama\"\n",
    "    #llm_model: str = \"phi\"\n",
    "    #llm_model: str = \"gemma2:2b\"\n",
    "    #llm_model: str = \"dolphin-phi\"\n",
    "    embedding_model: str = \"nomic-embed-text:v1.5\"\n",
    "    api_base_url: str = \"http://localhost:11434\"\n",
    "    chunk_size: int = 256  # Reduced chunk size\n",
    "    chunk_overlap: int = 5  # Reduced overlap\n",
    "    timeout: float = 60.0  # Increased timeout\n",
    "    max_retries: int = 3\n",
    "    retry_delay: float = 2.0\n",
    "    max_concurrent_requests: int = 3  # Limit concurrent requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab697e7b-61c3-4544-b8ef-c8c010d3471a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 174\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery execution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 174\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mrun(main())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machineLearning\\Lib\\asyncio\\runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug, loop_factory)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "class EHRDocument:\n",
    "    def __init__(self, patient_id: str, records: List[Dict]):\n",
    "        self.patient_id = patient_id\n",
    "        self.records = records\n",
    "\n",
    "    def to_string(self) -> str:\n",
    "        return json.dumps({\"patient_id\": self.patient_id, \"records\": self.records}, indent=2)\n",
    "\n",
    "class EHRSummarizer:\n",
    "    def __init__(self, config: OllamaConfig):\n",
    "        try:\n",
    "            timeout = Timeout(config.timeout)\n",
    "            \n",
    "            self.llm = Ollama(model=config.llm_model, base_url=config.api_base_url, timeout=timeout)\n",
    "            self.embed_model = OllamaEmbedding(model_name=config.embedding_model, base_url=config.api_base_url, timeout=timeout)\n",
    "            \n",
    "            Settings.llm = self.llm\n",
    "            Settings.embed_model = self.embed_model\n",
    "            Settings.chunk_size = config.chunk_size\n",
    "            Settings.chunk_overlap = config.chunk_overlap\n",
    "            \n",
    "            self.node_parser = SimpleNodeParser.from_defaults()\n",
    "            self.config = config\n",
    "            self.semaphore = asyncio.Semaphore(config.max_concurrent_requests)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to initialize EHRSummarizer: {e}\")\n",
    "            raise RuntimeError(f\"Initialization error: {e}\")\n",
    "\n",
    "    def create_index(self, ehr_documents: List[EHRDocument]):\n",
    "        try:\n",
    "            documents = [Document(text=doc.to_string(), id_=doc.patient_id) for doc in ehr_documents]\n",
    "            nodes = self.node_parser.get_nodes_from_documents(documents)\n",
    "            if not nodes:\n",
    "                raise ValueError(\"No nodes were created from the documents\")\n",
    "            self.index = VectorStoreIndex(nodes)\n",
    "            self.query_engine = self.index.as_query_engine()\n",
    "            logging.info(\"Index created successfully\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating index: {e}\")\n",
    "            raise RuntimeError(f\"Error creating index: {e}\")\n",
    "\n",
    "    @tenacity.retry(\n",
    "        stop=tenacity.stop_after_attempt(3),\n",
    "        wait=tenacity.wait_exponential(multiplier=1, min=2, max=10),\n",
    "        retry=tenacity.retry_if_exception_type((TimeoutException, HTTPStatusError, RequestError)),\n",
    "        reraise=True\n",
    "    )\n",
    "    async def _query_with_retry(self, prompt: str) -> str:\n",
    "        async with self.semaphore:\n",
    "            start_time = time.time()\n",
    "            response = await self.query_engine.aquery(prompt)\n",
    "            end_time = time.time()\n",
    "            logging.info(f\"Query execution time: {end_time - start_time:.2f} seconds\")\n",
    "            return response.response if hasattr(response, 'response') else str(response)\n",
    "\n",
    "    async def summarize_async(self, task: str, patient_id: Optional[str] = None) -> str:\n",
    "        try:\n",
    "            prompt = f\"For patient {patient_id}, {task}\" if patient_id else task\n",
    "            return await self._query_with_retry(prompt)\n",
    "        except TimeoutException as timeout_err:\n",
    "            logging.error(f\"Request timed out after retries: {timeout_err}\")\n",
    "            return \"The request timed out. Please try again later.\"\n",
    "        except HTTPStatusError as http_err:\n",
    "            logging.error(f\"HTTP error occurred after retries: {http_err}\")\n",
    "            return f\"HTTP error occurred: {http_err.response.status_code} - {http_err.response.text}\"\n",
    "        except RequestError as req_err:\n",
    "            logging.error(f\"Request error occurred after retries: {req_err}\")\n",
    "            return f\"Request error occurred: {req_err}\"\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An unexpected error occurred during summarization: {e}\")\n",
    "            return f\"An unexpected error occurred: {e}\"\n",
    "\n",
    "def load_sample_ehr_data() -> List[EHRDocument]:\n",
    "    return [\n",
    "        EHRDocument(\"P001\", [\n",
    "            {\"date\": \"2023-01-15\", \"type\": \"visit\", \"notes\": \"Patient complains of persistent cough for 2 weeks. Prescribed antibiotics.\"},\n",
    "            {\"date\": \"2023-02-01\", \"type\": \"lab\", \"result\": \"Blood test shows elevated white blood cell count.\"},\n",
    "            {\"date\": \"2023-02-10\", \"type\": \"visit\", \"notes\": \"Follow-up visit. Cough has improved. Continue current treatment.\"}\n",
    "        ]),\n",
    "        EHRDocument(\"P002\", [\n",
    "            {\"date\": \"2023-03-01\", \"type\": \"visit\", \"notes\": \"Annual check-up. Patient reports feeling well. No significant issues.\"},\n",
    "            {\"date\": \"2023-03-15\", \"type\": \"lab\", \"result\": \"Cholesterol levels slightly elevated. Recommend dietary changes.\"}\n",
    "        ])\n",
    "    ]\n",
    "\n",
    "async def process_query(summarizer: EHRSummarizer, task: str, patient_id: Optional[str]) -> str:\n",
    "    try:\n",
    "        return await summarizer.summarize_async(task, patient_id)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing query: {e}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "async def main():\n",
    "    config = OllamaConfig(\n",
    "        #llm_model=\"tinyllama\",\n",
    "        llm_model=\"qwen2:1.5b\",\n",
    "        #llm_model=\"phi\",\n",
    "        #llm_model: str = \"dolphin-phi\",\n",
    "        #llm_model: str = \"gemma2:2b\",\n",
    "        embedding_model=\"nomic-embed-text:v1.5\",\n",
    "        api_base_url=\"http://localhost:11434\",\n",
    "        chunk_size=256,\n",
    "        chunk_overlap=5,\n",
    "        timeout=60.0,\n",
    "        max_retries=3,\n",
    "        retry_delay=2.0,\n",
    "        max_concurrent_requests=3\n",
    "    )\n",
    "\n",
    "    summarizer = EHRSummarizer(config)\n",
    "    ehr_data = load_sample_ehr_data()\n",
    "\n",
    "    summarizer.create_index(ehr_data)\n",
    "\n",
    "    logging.info(\"EHR Summarization System initialized. You can start asking for summaries.\")\n",
    "    print(\"Type 'quit' to exit.\")\n",
    "\n",
    "    while True:\n",
    "        print(\"\\nChoose a summarization task:\")\n",
    "        print(\"1. Summarize patient history\")\n",
    "        print(\"2. List all medications\")\n",
    "        print(\"3. Summarize lab results\")\n",
    "        print(\"4. Custom query\")\n",
    "        print(\"5. Batch process all patients\")\n",
    "        \n",
    "        choice = input(\"Enter your choice (1-5): \")\n",
    "        \n",
    "        if choice.lower() == 'quit':\n",
    "            break\n",
    "\n",
    "        if choice == \"5\":\n",
    "            tasks = [\n",
    "                \"Provide a concise summary of the patient's medical history.\",\n",
    "                \"List all medications prescribed to the patient.\",\n",
    "                \"Summarize all lab results for the patient.\"\n",
    "            ]\n",
    "            patient_ids = [doc.patient_id for doc in ehr_data]\n",
    "            \n",
    "            start_time = time.time()\n",
    "            results = await asyncio.gather(*[process_query(summarizer, task, patient_id) \n",
    "                                             for task in tasks \n",
    "                                             for patient_id in patient_ids])\n",
    "            end_time = time.time()\n",
    "            \n",
    "            print(\"\\nBatch Processing Results:\")\n",
    "            for i, result in enumerate(results):\n",
    "                print(f\"\\nTask {(i // len(patient_ids)) + 1}, Patient {patient_ids[i % len(patient_ids)]}:\")\n",
    "                print(result)\n",
    "            \n",
    "            print(f\"\\nTotal batch processing time: {end_time - start_time:.2f} seconds\")\n",
    "        else:\n",
    "            patient_id = input(\"Enter patient ID (or press Enter for all patients): \")\n",
    "\n",
    "            if choice == \"1\":\n",
    "                task = \"Provide a concise summary of the patient's medical history.\"\n",
    "            elif choice == \"2\":\n",
    "                task = \"List all medications prescribed to the patient.\"\n",
    "            elif choice == \"3\":\n",
    "                task = \"Summarize all lab results for the patient.\"\n",
    "            elif choice == \"4\":\n",
    "                task = input(\"Enter your custom query: \")\n",
    "            else:\n",
    "                print(\"Invalid choice. Please try again.\")\n",
    "                continue\n",
    "\n",
    "            start_time = time.time()\n",
    "            summary = await process_query(summarizer, task, patient_id if patient_id else None)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            print(f\"\\nSummary: {summary}\")\n",
    "            print(f\"Query execution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424be73-6bd6-4b53-a278-095d249e1afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
